{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from alexnet_model import AlexNet\n",
    "\n",
    "# Function to prepare data for training and testing\n",
    "def train_alexnet():\n",
    "    # load, resize, normalize image\n",
    "    train_data = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255 # normalizes pixel values to the range [0,1]\n",
    "    )\n",
    "    \n",
    "    test_data = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    # Loading Training and Testing Data\n",
    "    train_generator = train_data.flow_from_directory(\n",
    "        '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Train',\n",
    "        target_size=(227, 227), # match AlexNet\n",
    "        batch_size=128, # number of images per batch\n",
    "        class_mode='categorical' # set labels to one-hot encoded vectors for multi-class\n",
    "    )\n",
    "    \n",
    "    test_generator = test_data.flow_from_directory(\n",
    "       '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Test',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=128,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    # Create AlexNet Model\n",
    "    model = AlexNet(num_classes=50)\n",
    "    \n",
    "    # Optimizer (SGD)\n",
    "    optimizer = tf.keras.optimizers.SGD( \n",
    "        learning_rate=0.01, # initial learning rate\n",
    "        momentum=0.9, # helps to accelerate convergence\n",
    "        nesterov=True\n",
    "    )\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy', # loss function\n",
    "        metrics=['accuracy'] # tracking accuracy\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        # trains on 20 epochs using data from \"train_generator\" and validates on \"test_generator\"\n",
    "        train_generator,\n",
    "        epochs=20,\n",
    "        validation_data=test_generator,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.LearningRateScheduler(\n",
    "                lambda epoch: 0.01 if epoch < 10 else (0.001 if epoch < 15 else 0.0001) # dynamically adjusting learning rate (like in original AlexNet)\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'alexnet_checkpoint.keras', # checkpoints whenever accuracy improves\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Savel final weights\n",
    "    model.save_weights('alexnet_final.keras')\n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history = train_alexnet()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
