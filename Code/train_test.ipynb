{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Mesa: 1243 training images, 311 test images\n",
      "Processed Colorado Springs: 1814 training images, 454 test images\n",
      "Processed Detroit: 1982 training images, 496 test images\n",
      "Processed Fort Worth: 1523 training images, 381 test images\n",
      "Processed Austin: 1982 training images, 496 test images\n",
      "Processed Sacramento: 1971 training images, 493 test images\n",
      "Processed Atlanta: 1960 training images, 490 test images\n",
      "Processed New Yorkd: 2128 training images, 532 test images\n",
      "Processed Columbus: 2083 training images, 521 test images\n",
      "Processed Wichita: 1758 training images, 440 test images\n",
      "Processed Bakersfield: 2016 training images, 504 test images\n",
      "Processed Baltimorem: 1131 training images, 283 test images\n",
      "Processed Minneapolis: 2161 training images, 541 test images\n",
      "Processed Fresno: 1736 training images, 434 test images\n",
      "Processed Louisvillel: 1568 training images, 392 test images\n",
      "Processed Washingtonk: 918 training images, 230 test images\n",
      "Processed Kansas City: 1892 training images, 474 test images\n",
      "Processed Seattle: 1971 training images, 493 test images\n",
      "Processed Chicago: 1848 training images, 462 test images\n",
      "Processed Los Angeles: 2072 training images, 518 test images\n",
      "Processed Phoenix: 1848 training images, 462 test images\n",
      "Processed Raleigh: 2105 training images, 527 test images\n",
      "Processed Portland: 2161 training images, 541 test images\n",
      "Processed Tucson: 604 training images, 152 test images\n",
      "Processed Omaha: 2004 training images, 502 test images\n",
      "Processed Albuquerque: 1904 training images, 476 test images\n",
      "Processed Houston: 2094 training images, 524 test images\n",
      "Processed Indianapolisg: 2072 training images, 518 test images\n",
      "Processed Las Vegas: 1825 training images, 457 test images\n",
      "Processed Tampa: 2172 training images, 544 test images\n",
      "Processed Charlotte: 2139 training images, 535 test images\n",
      "Processed Virginia Beachm: 89 training images, 23 test images\n",
      "Processed Boston: 694 training images, 174 test images\n",
      "Processed Philadelphiae: 2161 training images, 541 test images\n",
      "Processed Dallas: 2105 training images, 527 test images\n",
      "Processed San Antonio: 2217 training images, 555 test images\n",
      "Processed San Diego: 1388 training images, 348 test images\n",
      "Processed Long Beach: 1825 training images, 457 test images\n",
      "Processed Miami: 2150 training images, 538 test images\n",
      "Processed Nashvillej: 1915 training images, 479 test images\n",
      "Processed San Jose: 2072 training images, 518 test images\n",
      "Processed Tulsa: 1904 training images, 476 test images\n",
      "Processed Denveri: 1915 training images, 479 test images\n",
      "Processed Jacksonvillef: 1915 training images, 479 test images\n",
      "Processed Oklahoma City: 1892 training images, 474 test images\n",
      "Processed Milwaukee: 2116 training images, 530 test images\n",
      "Processed San Franciscoh: 2161 training images, 541 test images\n",
      "Processed El Paso: 1041 training images, 261 test images\n",
      "Processed Oakland: 1646 training images, 412 test images\n",
      "Processed Memphis: 2004 training images, 502 test images\n",
      "\n",
      "Final split:\n",
      "Training images: 89896\n",
      "Test images: 22498\n",
      "Total images: 112394\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function for traintestsplit \n",
    "def create_train_test_split(source_dir, train_dir, test_dir, test_size = 0.2):\n",
    "    # ensuring that directories exist, if not they are created\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # iterating through subdirectories (cities)\n",
    "    for city in os.listdir(source_dir):\n",
    "        city_dir = os.path.join(source_dir, city)\n",
    "        \n",
    "        # skipping non directories\n",
    "        if not os.path.isdir(city_dir):\n",
    "            continue\n",
    "        \n",
    "        # collecting image files\n",
    "        images = [f for f in os.listdir(city_dir) if f.endswith((\".jpg\"))]\n",
    "\n",
    "        # Splitting images into Training and Testing Sets\n",
    "        train_images, test_images = train_test_split(\n",
    "            images,\n",
    "            test_size = test_size, # specified earlier\n",
    "            random_state = 42\n",
    "        )\n",
    "\n",
    "        # creating subdirectories in train & test directories for each city\n",
    "        os.makedirs(os.path.join(train_dir, city), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, city), exist_ok=True)\n",
    "\n",
    "        # Copying Training images\n",
    "        for img in train_images:\n",
    "            src = os.path.join(city_dir, img)\n",
    "            dst = os.path.join(train_dir, city, img)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "        # Copying Testing images\n",
    "        for img in test_images:\n",
    "            src = os.path.join(city_dir, img)\n",
    "            dst = os.path.join(test_dir, city, img)\n",
    "            shutil.copy2(src,dst)\n",
    "        \n",
    "        print(f'Processed {city}: {len(train_images)} training images, {len(test_images)} test images')\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Specifying the path for source, train, and test directories\n",
    "    source_directory = '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Processed'\n",
    "    test_directory = '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Test'\n",
    "    train_directory = '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Train'\n",
    "\n",
    "    # Calling Split function\n",
    "    create_train_test_split(source_directory, train_directory, test_directory)\n",
    "\n",
    "    train_count = sum([len(files) for r, d, files in os.walk(train_directory)])\n",
    "    test_count = sum([len(files) for r, d, files in os.walk(test_directory)])\n",
    "    \n",
    "    # Little summary\n",
    "    print(f\"\\nFinal split:\")\n",
    "    print(f\"Training images: {train_count}\")\n",
    "    print(f\"Test images: {test_count}\")\n",
    "    print(f\"Total images: {train_count + test_count}\")\n",
    "\n",
    "# This makes sure, that the script only runs when executed directly and not when imported as a module\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Val Split\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set path to data\n",
    "original_data_dir = '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Train'\n",
    "\n",
    "# new directory for train and val data\n",
    "train_dir = '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Train1'\n",
    "val_dir = '/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Data/Val'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# For every city\n",
    "for city in os.listdir(original_data_dir):\n",
    "    city_path = os.path.join(original_data_dir, city)\n",
    "    if os.path.isdir(city_path): \n",
    "        # List all images in class\n",
    "        images = os.listdir(city_path)\n",
    "        \n",
    "        # Split: 80% Training, 20% Validation\n",
    "        train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # path destination\n",
    "        train_city_dir = os.path.join(train_dir, city)\n",
    "        val_city_dir = os.path.join(val_dir, city)\n",
    "        \n",
    "        os.makedirs(train_city_dir, exist_ok=True)\n",
    "        os.makedirs(val_city_dir, exist_ok=True)\n",
    "        \n",
    "        # copy images\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(city_path, img), os.path.join(train_city_dir, img))\n",
    "        \n",
    "        for img in val_images:\n",
    "            shutil.copy(os.path.join(city_path, img), os.path.join(val_city_dir, img))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
