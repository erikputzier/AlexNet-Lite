{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kagglehub\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Download latest version (Set this to False the first time you are running the script to download the data)\n",
    "is_downloaded = True\n",
    "\n",
    "if is_downloaded:\n",
    "    print(\"Data is already downloaded\")\n",
    "else:\n",
    "    path = kagglehub.dataset_download(\"pinstripezebra/google-streetview-top-50-us-cities\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Set the directory containing your images (Change this to your directory)\n",
    "image_folder = r'/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Images'\n",
    "base_output_folder = r'/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/Processed'\n",
    "\n",
    "# Create the base output directory\n",
    "os.makedirs(base_output_folder, exist_ok=True)\n",
    "\n",
    "target_size = (227, 227) # Target size for resized images\n",
    "max_images_per_city = 1000  # Maximum number of processed images per city\n",
    "num_patches = 5  # Number of patches to extract per image\n",
    "\n",
    "# Load the reference \"no imagery\" image\n",
    "reference_image_path = r'/Users/maximilianstumpf/Desktop/UCLA/Math156 - Machine Learning/Project/No imagery/No_photo.jpg'\n",
    "reference_image = Image.open(reference_image_path).convert('L')  # Convert reference to grayscale too\n",
    "\n",
    "# Statistics tracking with augmentation stats added\n",
    "processed_stats = defaultdict(lambda: {\n",
    "    'total': 0, \n",
    "    'processed': 0, \n",
    "    'augmented': 0,\n",
    "    'errors': 0,\n",
    "    'no_imagery': 0\n",
    "})\n",
    "# Function to check if an image is \"no imagery\"\n",
    "def is_no_imagery_image(img_path, reference_image):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L') # convert image to grayscale\n",
    "        img = img.resize(reference_image.size) # resize to match the reference\n",
    "        diff = ImageChops.difference(reference_image, img) # compute pixel differences\n",
    "        if diff.getbbox() is None: \n",
    "            return True\n",
    "        img_array = np.array(img)\n",
    "        std = np.std(img_array)\n",
    "        return std < 5 # low variance indicates uniform image\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking no imagery for {img_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Function to extract city name from filename\n",
    "def get_city_name(filename):\n",
    "    patterns = [\n",
    "        r\"([A-Za-z]+)(?:_\\d+)?(?:_ \\([-\\d.]+, [-\\d.]+\\))?\\.jpg\", # CityName_XYZ.jpg format\n",
    "        r\"([A-Za-z]+[ A-Za-z]+)(?:_\\d+)?(?:_ \\([-\\d.]+, [-\\d.]+\\))?\\.jpg\", # Multi-word city names\n",
    "        r\"([A-Za-z]+[.]?[ ]?[A-Za-z]+)(?:_\\d+)?(?:_ \\([-\\d.]+, [-\\d.]+\\))?\\.jpg\" # edge cases\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            return match.group(1).replace(\" \", \"_\") # replace spaces with underscores\n",
    "    return None\n",
    "\n",
    "# Function to apply augmentations\n",
    "def apply_augmentations(img):\n",
    "    augmented_images = []\n",
    "    \n",
    "    # List of augmentation functions\n",
    "    augmentations = [\n",
    "        ('flip_h', lambda x: x.transpose(Image.FLIP_LEFT_RIGHT)), # horizontal flip\n",
    "        ('flip_v', lambda x: x.transpose(Image.FLIP_TOP_BOTTOM)), # Vertical flip\n",
    "        ('rotate90', lambda x: x.rotate(90)), # rotate by 90 degress\n",
    "        ('bright_up', lambda x: ImageEnhance.Brightness(x).enhance(1.2)), # increase brightness\n",
    "        ('bright_down', lambda x: ImageEnhance.Brightness(x).enhance(0.8)), # decrease brightness\n",
    "        ('contrast_up', lambda x: ImageEnhance.Contrast(x).enhance(1.2)), # increase contrast\n",
    "        ('contrast_down', lambda x: ImageEnhance.Contrast(x).enhance(0.8)) # decrease contrast\n",
    "    ]\n",
    "    \n",
    "    # Apply each augmentation\n",
    "    for aug_name, aug_func in augmentations:\n",
    "        try:\n",
    "            aug_img = aug_func(img)\n",
    "            augmented_images.append((aug_name, aug_img))\n",
    "        except Exception as e:\n",
    "            print(f\"Error applying {aug_name} augmentation: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return augmented_images\n",
    "\n",
    "# Function to process and resize image\n",
    "def process_image(img):\n",
    "    \"\"\"Convert image to grayscale and resize\"\"\"\n",
    "    gray_img = img.convert('L')\n",
    "    return gray_img.resize(target_size)\n",
    "\n",
    "# Function to extract random crops\n",
    "def random_crop(img):\n",
    "    width, height = img.size\n",
    "    if width < 227 or height < 227:\n",
    "        raise ValueError(\"Image size must be at least 227x227 for cropping.\")\n",
    "    \n",
    "    x = random.randint(0, width - 227)\n",
    "    y = random.randint(0, height - 227)\n",
    "    \n",
    "    return img.crop((x, y, x + 227, y + 227))\n",
    "\n",
    "# Function to extract random patches and apply augmentation to each patch\n",
    "def extract_patches(img, num_patches=5):\n",
    "    patches = []\n",
    "    gray_img = img if img.mode == 'L' else img.convert('L')\n",
    "    \n",
    "    for i in range(num_patches):\n",
    "        try:\n",
    "            patch = random_crop(gray_img) # Extract original patch\n",
    "            patches.append(('original', patch)) # Add original patch with identifier\n",
    "            augmented_patches = apply_augmentations(patch) # Add augmented versions of the patch\n",
    "            patches.extend(augmented_patches)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error extracting patch {i}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    return patches\n",
    "\n",
    "# Group files by city and remove no imagery files\n",
    "print(\"\\nGrouping files by city and checking for no imagery...\")\n",
    "city_files = defaultdict(list)\n",
    "for filename in os.listdir(image_folder):\n",
    "    file_path = os.path.join(image_folder, filename)\n",
    "    \n",
    "    if is_no_imagery_image(file_path, reference_image): # skip \"no imagery\" files\n",
    "        city_name = get_city_name(filename)\n",
    "        if city_name:\n",
    "            processed_stats[city_name]['no_imagery'] += 1\n",
    "        print(f\"Found no imagery file: {filename}\")\n",
    "        continue\n",
    "        \n",
    "    city_name = get_city_name(filename)\n",
    "    if city_name:\n",
    "        city_files[city_name].append(filename)\n",
    "        processed_stats[city_name]['total'] += 1\n",
    "\n",
    "print(\"\\nInitial city statistics:\")\n",
    "for city, stats in processed_stats.items():\n",
    "    print(f\"{city}: {stats['total']} usable images found ({stats['no_imagery']} no imagery files skipped)\")\n",
    "\n",
    "# Process images for each city\n",
    "print(\"\\nProcessing images with augmentations...\")\n",
    "for city, files in city_files.items():\n",
    "    print(f\"\\nProcessing {city}...\")\n",
    "    \n",
    "    city_output_folder = os.path.join(base_output_folder, city)\n",
    "    os.makedirs(city_output_folder, exist_ok=True) # create city folder\n",
    "    \n",
    "    # Calculate how many original images we need to process\n",
    "    # Each original image will produce multiple augmented versions\n",
    "    augmentation_factor = 8  # original + 7 augmentations\n",
    "    images_per_original = (1 + num_patches) * augmentation_factor\n",
    "    originals_needed = min(len(files), max_images_per_city // images_per_original)\n",
    "    \n",
    "    for filename in files[:originals_needed]:\n",
    "        file_path = os.path.join(image_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                # Process original image\n",
    "                processed_img = process_image(img) # resize\n",
    "                \n",
    "                # Save original resized version\n",
    "                resized_output_path = os.path.join(city_output_folder, f\"resized_original_{filename}\")\n",
    "                processed_img.save(resized_output_path)\n",
    "                processed_stats[city]['processed'] += 1\n",
    "                \n",
    "                # Save augmented versions of full image\n",
    "                augmented_images = apply_augmentations(processed_img) # augment resized pic\n",
    "                for aug_name, aug_img in augmented_images:\n",
    "                    aug_output_path = os.path.join(city_output_folder, f\"resized_{aug_name}_{filename}\")\n",
    "                    aug_img.save(aug_output_path)\n",
    "                    processed_stats[city]['augmented'] += 1\n",
    "                \n",
    "                # Extract and save patches with their augmentations\n",
    "                try:\n",
    "                    patches = extract_patches(img, num_patches=num_patches) # extract & augment patches\n",
    "                    for i, (patch_type, patch) in enumerate(patches):\n",
    "                        patch_output_path = os.path.join(\n",
    "                            city_output_folder, \n",
    "                            f\"patch_{i//augmentation_factor + 1}_{patch_type}_{filename}\"\n",
    "                        )\n",
    "                        patch.save(patch_output_path)\n",
    "                        if patch_type == 'original':\n",
    "                            processed_stats[city]['processed'] += 1\n",
    "                        else:\n",
    "                            processed_stats[city]['augmented'] += 1\n",
    "                            \n",
    "                    print(f\"Successfully processed {filename} for {city} with augmentations\")\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing patches for {filename}: {e}\")\n",
    "                    processed_stats[city]['errors'] += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            processed_stats[city]['errors'] += 1\n",
    "\n",
    "# Print final processing statistics\n",
    "print(\"\\nFinal Processing Statistics:\")\n",
    "print(\"-\" * 110)\n",
    "print(f\"{'City':<20} {'Original Files':<15} {'No Imagery':<15} {'Processed':<12} {'Augmented':<12} {'Errors':<12}\")\n",
    "print(\"-\" * 110)\n",
    "for city, stats in processed_stats.items():\n",
    "    print(f\"{city:<20} {stats['total']:<15} {stats['no_imagery']:<15} {stats['processed']:<12} {stats['augmented']:<12} {stats['errors']:<12}\")\n",
    "\n",
    "# Verify final counts\n",
    "print(\"\\nVerifying final image counts per city...\")\n",
    "for city in city_files.keys():\n",
    "    city_folder = os.path.join(base_output_folder, city)\n",
    "    if os.path.exists(city_folder):\n",
    "        file_count = len(os.listdir(city_folder))\n",
    "        print(f\"{city}: {file_count} total processed files\")\n",
    "    else:\n",
    "        print(f\"Warning: No output folder found for {city}\")\n",
    "\n",
    "print(\"\\nProcessing complete. All images converted to grayscale, augmented, and saved to city-specific folders.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
